{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b00246929f82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "\n",
    "# Read the csv file\n",
    "df = pd.read_csv('reviews2.csv')\n",
    "\n",
    "# findinf frequence of words\n",
    "def freq_words(x, terms = 30):\n",
    "    all_words = ' '.join([str(text) for text in x])\n",
    "    all_words = all_words.split()\n",
    "  \n",
    "    fdist = FreqDist(all_words)\n",
    "    words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})\n",
    "    \n",
    "    # selecting top 20 most frequent words\n",
    "    d = words_df.nlargest(columns=\"count\", n = terms) \n",
    "    plt.figure(figsize=(20,5))\n",
    "    ax = sns.barplot(data=d, x= \"word\", y = \"count\")\n",
    "    ax.set(ylabel = 'Count')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# replace \"n't\" with \" not\"\n",
    "df['Review'] = df['Review'].str.replace(\"n\\'t\", \" not\")\n",
    "\n",
    "# remove unwanted characters, numbers and symbols\n",
    "df['Review'] = df['Review'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "\n",
    "\n",
    "\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(rev):\n",
    "    rev_new = \" \".join([i for i in rev if i not in stopwords.words('english')])\n",
    "    return rev_new\n",
    "\n",
    "# remove short words (length < 3)\n",
    "df['Review'] = df['Review'].apply(lambda x: ' '.join([str(w) for w in str(x).split() if len(w)>2]))\n",
    "\n",
    "# remove stopwords from the text\n",
    "reviews = [remove_stopwords(r.split()) for r in df['Review']]\n",
    "\n",
    "# make entire text lowercase\n",
    "reviews = [r.lower() for r in reviews]\n",
    "\n",
    "# user porterstemmer for stemming\n",
    "def stemming(texts): \n",
    "    s_stemmer = PorterStemmer()\n",
    "    for i in range(len(texts)):\n",
    "        texts[i]=[s_stemmer.stem(texts[i][j]) for j in range(len(texts[i]))]\n",
    "        return texts\n",
    "        \n",
    "tokenized_reviews = pd.Series(reviews).apply(lambda x: x.split())\n",
    "reviews_2 = stemming(tokenized_reviews)\n",
    "\n",
    "    \n",
    "# Create the term dictionary of our corpus, where every unique term is assigned an index\n",
    "dictionary = corpora.Dictionary(reviews_2)#reviews_2)\n",
    "\n",
    "# Convert list of reviews (reviews_2) into a Document Term Matrix using the dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(rev) for rev in reviews_2]#reviews_2]\n",
    "\n",
    "# Creating the object for LDA model using gensim library\n",
    "LDA = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = LDA(corpus=doc_term_matrix,\n",
    "                id2word=dictionary,\n",
    "                num_topics=7, \n",
    "                random_state=100,\n",
    "                chunksize=1000,\n",
    "                passes=50)\n",
    "\n",
    "lda_model.print_topics()\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\n",
    "vis\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "lda_model.print_topics()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
