{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# findinf frequence of words\n",
    "def freq_words(x, terms = 30):\n",
    "    all_words = ' '.join([str(text) for text in x])\n",
    "    all_words = all_words.split()\n",
    "  \n",
    "    fdist = FreqDist(all_words)\n",
    "    words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})\n",
    "    \n",
    "    # selecting top 20 most frequent words\n",
    "    d = words_df.nlargest(columns=\"count\", n = terms) \n",
    "    plt.figure(figsize=(20,5))\n",
    "    ax = sns.barplot(data=d, x= \"word\", y = \"count\")\n",
    "    ax.set(ylabel = 'Count')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove stopwords\n",
    "def remove_stopwords(rev):\n",
    "    rev_new = \" \".join([i for i in rev if i not in stopwords.words('english')])\n",
    "    return rev_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user porterstemmer for stemming\n",
    "def stemming(texts): \n",
    "    s_stemmer = PorterStemmer()\n",
    "    for i in range(len(texts)):\n",
    "        texts[i]=[s_stemmer.stem(texts[i][j]) for j in range(len(texts[i]))]\n",
    "        return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file\n",
    "df = pd.read_csv('reviews2.csv')\n",
    "\n",
    "\n",
    "# replace \"n't\" with \" not\"\n",
    "df['Review'] = df['Review'].str.replace(\"n\\'t\", \" not\")\n",
    "\n",
    "# remove unwanted characters, numbers and symbols\n",
    "df['Review'] = df['Review'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "\n",
    "# remove short words (length < 3)\n",
    "df['Review'] = df['Review'].apply(lambda x: ' '.join([str(w) for w in str(x).split() if len(w)>2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from the text\n",
    "reviews = [remove_stopwords(r.split()) for r in df['Review']]\n",
    "\n",
    "# make entire text lowercase\n",
    "reviews = [r.lower() for r in reviews]\n",
    "        \n",
    "tokenized_reviews = pd.Series(reviews).apply(lambda x: x.split())\n",
    "reviews_2 = stemming(tokenized_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the term dictionary of our corpus, where every unique term is assigned an index\n",
    "dictionary = corpora.Dictionary(reviews_2)#reviews_2)\n",
    "\n",
    "# Convert list of reviews (reviews_2) into a Document Term Matrix using the dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(rev) for rev in reviews_2]#reviews_2]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews# Creating the object for LDA model using gensim library\n",
    "LDA = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = LDA(corpus=doc_term_matrix,\n",
    "                id2word=dictionary,\n",
    "                num_topics=7, \n",
    "                random_state=100,\n",
    "                chunksize=1000,\n",
    "                passes=50)\n",
    "\n",
    "lda_model.print_topics()\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\n",
    "vis\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "lda_model.print_topics() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
